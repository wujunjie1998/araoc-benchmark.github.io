<html>
  <head>
    <title>
      Understanding LLMsâ€™ Fluid Intelligence Deficiency: An Analysis of the ARC Task 
    </title>
    <link
      rel="icon"
      href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 32 32%22><text y=%2226%22 font-size=%2232%22>ðŸ¦œ</text></svg>"
    />
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="./css/index.css" />
  </head>

  <body>
    <div class="header">
      <div class="paper-title">
        Understanding LLMsâ€™ Fluid Intelligence Deficiency:
        <br />
        An Analysis of the ARC Task
      </div>
      <div>
        <!-- * Paper -->
        <span class="link-block">
          <a target="_blank" href="./paper.pdf"
            ><img
              class="badge"
              src="https://img.shields.io/badge/Paper-PDF-red?&labelColor=lightgray&logo=arxiv&logoColor=brown" /><img
          /></a>
        </span>
        <!-- * Dataset -->
        <!--
        <span class="link-block">
          <a
            target="_blank"
            href="https://huggingface.co/datasets/ShunchiZhang/PhysiCo/"
            ><img
              class="badge"
              src="https://img.shields.io/badge/HuggingFace-Dataset-yellow?labelColor=lightgray&logo=huggingface" /><img
          /></a>
        </span>
        -->

        <!-- * Code -->
         <!--
        <span class="link-block">
          <a target="_blank" href="https://github.com/physico-benchmark/physico"
            ><img
              class="badge"
              src="https://img.shields.io/badge/GitHub-Code-gray?labelColor=lightgray&logo=github&logoColor=gray" /><img /></a
        ></span>
        -->
        <!-- * Leaderboard -->
        <!--
        <span class="link-block">
          <a href="./leaderboard.html"
            ><img
              class="badge"
              src="https://img.shields.io/badge/Leaderboard-Visit-blue?labelColor=lightgray&logo=stackblitz&logoColor=367BAF" /><img /></a
        ></span>
        -->
        <!-- * X Threads -->
        <!--
        <span class="link-block">
          <a href="https://x.com/jieeijjie/status/1876713099752861782"
            ><img
              class="badge"
              src="https://img.shields.io/badge/Threads-black?labelColor=lightgray&logo=x&logoColor=gray" /><img /></a
        ></span>
        -->

      </div>
      <div>
        <div class="author-list">
          <span class="author-block"
            ><a href="https://wujunjie1998.github.io/">Junjie Wu</a
            ><sup>1</sup></span
          >
          <span class="author-block"
            ><a href="https://sites.google.com/site/moyunlp/">Mo Yu</a
            ><sup>2</sup></span
          >
          <span class="author-block"
            ><a href="https://lemaoliu.github.io">Lemao Liu</a
            ><sup>2</sup></span
          >
          <span class="author-block"
            ><a href="https://sites.google.com/view/dyyeung">Dit-Yan Yeung</a
            ><sup>1</sup></span
          >
          <span class="author-block"
            ><a href="https://openreview.net/profile?id=~Jie_Zhou8">Jie Zhou</a
            ><sup>2</sup></span
          >
        </div>
        <div class="inst-list">
          <span class="institution-block"><sup>1</sup> Hong Kong University of Science and Technology</span>
          <span class="institution-block"><sup>2</sup> WeChat AI</span>
        </div>
      </div>
    </div>
    <!--
    <div class="teaser">
      <center>
        <img src="./img/teaser.png" />
        <figcaption>
          Illustration of a "Stochastic Parrot ðŸ¦œ" by our
          <span class="dataset-name">PhysiCo</span> task consisting of both
          <b style="color: #a47b48">low-level</b> and
          <b style="color: #153cf9">high-level</b> subtasks in parallel. For a
          concept <i>Gravity</i>, an LLM can generate its accurate description
          in natural language, but cannot interpret its grid-format
          illustration.
        </figcaption>
      </center>
    </div>
  -->
    <hr />

    <!-- ^ Summary of Our Research -->
    <center><h1>Summary of Our Research</h1></center>
    <div class="content">
      <!-- <p style="font-size: large; text-align: center">
        <b>TL;DR:</b>
      </p> -->
      <p>
        While LLMs have exhibited strong performance on various NLP tasks, it is noteworthy that most of these tasks rely on utilizing the vast amount of knowledge encoded in LLMsâ€™ parameters, rather than solving new problems without prior knowledge. In cognitive research, the latter ability is referred to as <strong>fluid intelligence</strong>, which is considered to be critical for assessing human intelligence. Recent research on fluid intelligence assessments has highlighted significant deficiencies in LLMsâ€™ abilities. In this paper, we analyze the challenges LLMs face in demonstrating fluid intelligence through controlled experiments, using the most representative ARC task as an example. Our study revealed three major limitations in existing LLMs:
      </p>
      <ol>
        <li>limited ability for skill composition;</li>
        <li>
          unfamiliarity with abstract input formats;
        </li>
        <li>
          the intrinsic deficiency of left-to-right decoding.
        </li>
      </ol>
    </div>
   
  
    <!-- ^ Our Studies and Findings -->
    <center><h1>The Abstraction and Reasoning Challenge (ARC) is suitable for evaluating fluid intelligence for LLMs.</h1></center>
    <div class="content">
      <!-- <p>Foo Bar</p> -->
      <center>
        <img src="./img/fluid1.png" width="70%" />
        <figcaption style="text-align: center">
          Existing inductive reasoning tasks fail to prevent LLMs from using memorization shortcuts, making those tasks easier for LLMs to solve. On the contrary, due to the abstract nature of ARC tasks, LLMs cannot rely on memorization or external knowledge to easily solve them, making ARC suitable for evaluating fluid intelligence for LLMs.
        </figcaption> 
      </center>
    </div>


    <!-- ^ Our Studies and Findings -->
    <center><h1>However, even strong LLMs perform poorly on ARC tasks.</h1></center>
    <div class="content">
      <!-- <p>Foo Bar</p> -->
      <center>
        <img src="./img/fluid2.png" width="40%" />
        <figcaption style="text-align: center">
          Existing inductive reasoning tasks fail to prevent LLMs from using memorization shortcuts, making those tasks easier for LLMs to solve. On the contrary, due to the abstract nature of ARC tasks, LLMs cannot rely on memorization or external knowledge to easily solve them, making ARC suitable for evaluating fluid intelligence for LLMs.
        </figcaption> 
      </center>
    </div>

    <!-- ^ Our Studies and Findings -->
    <center><h1>We analyze the challenges of LLMs on fluid intelligence from a task decomposition perspective. </h1></center>
    <div class="content">
      <!-- <p>Foo Bar</p> -->
      <center>
        <img src="./img/fluid3.png" width="70%" />
        <figcaption style="text-align: center">
          We conclude six atomic operations that can compose the transformation rules for most of the ARC tasks, and build an ARC-style benchmark upon these atomic operations (<strong>ARAOC</strong>).
        </figcaption> 
      </center>
    </div>

    <!-- ^ Our Studies and Findings -->
    <center><h1>Suprisingly, the evaluation results on ARAOC show that LLMs still encounter substantial difficulties with tasks related to Move, Copy, Mirror, and Scale.</h1></center>
    <div class="content">
      <!-- <p>Foo Bar</p> -->
      <center>
        <img src="./img/fluid4.png" width="70%" />
        <!--
        <figcaption style="text-align: center">
          
        </figcaption> 
      </center>
    -->
    </div>

    <center><h1>These results motivate us to perform several controllable experiments on ARAOC and ARC, and reveal the challenges of LLMs on internal factors, task composition, input format as well as modeling with left-to-right Transformer.</h1></center>
    <div class="content">
    
  </body>
</html>
